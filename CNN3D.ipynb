{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros([10,10,10])\n",
    "obj = ['sphere', 'cylinder', 'cube']\n",
    "X = np.asarray([None])\n",
    "Y = np.asarray([None])\n",
    "\n",
    "\n",
    "for i in range(1000):\n",
    "    \n",
    "    shape = np.random.choice([0,1,2])\n",
    "    xs = np.copy(x)\n",
    "    \n",
    "    if shape == 0:\n",
    "        for j in range(10000):\n",
    "            px, py, pz = np.random.uniform(0, 10, 3)\n",
    "            dist = np.sqrt((px-5)**2 + (py-5)**2 + (pz-5)**2)\n",
    "            if dist <= 3:\n",
    "                a = int(np.floor(px))\n",
    "                b = int(np.floor(py))\n",
    "                c = int(np.floor(pz))\n",
    "                xs[a,b,c] += 1\n",
    "    \n",
    "    elif shape == 1:\n",
    "        for j in range(1000):\n",
    "            px, py, pz = np.random.uniform(0, 10, 3)\n",
    "            dist = np.sqrt((px-5)**2 + (py-5)**2)\n",
    "            if (dist <= 3) and (np.abs(pz-5) <= 3):\n",
    "                a = int(np.floor(px))\n",
    "                b = int(np.floor(py))\n",
    "                c = int(np.floor(pz))\n",
    "                xs[a,b,c] += 1\n",
    "                \n",
    "    elif shape == 2:\n",
    "        for j in range(1000):\n",
    "            px, py, pz = np.random.uniform(0, 10, 3)\n",
    "            if np.abs(px-5) <= 3 and np.abs(py-5) <= 3 and np.abs(pz-5) <= 3:\n",
    "                a = int(np.floor(px))\n",
    "                b = int(np.floor(py))\n",
    "                c = int(np.floor(pz))\n",
    "                xs[a,b,c] += 1\n",
    "               \n",
    "    if X.all() == None:\n",
    "        X = np.expand_dims(xs, 0)\n",
    "        Y = np.asarray([shape])\n",
    "    else:\n",
    "        X = np.concatenate([X, np.expand_dims(xs, 0)])\n",
    "        Y = np.concatenate([Y, [shape]])\n",
    "        \n",
    "    del xs\n",
    "del x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random.normal([5,5,5,1,8], 0, 0.1))\n",
    "b1 = tf.Variable(tf.random.normal([8]))\n",
    "\n",
    "W2 = tf.Variable(tf.random.normal([3,3,3,8,16],0,0.1))\n",
    "b2 = tf.Variable(tf.random.normal([16]))\n",
    "\n",
    "W3 = tf.Variable(tf.random.normal([3*3*3*16, 3],0,0.1))\n",
    "b3 = tf.Variable(tf.random.normal([3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = normalize(X)\n",
    "data = np.expand_dims(data, axis=-1)\n",
    "data = data.astype(np.float32)\n",
    "labels = tf.one_hot(Y, 3, on_value=1., off_value=0., axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    num, d, w, h = x.shape\n",
    "    data = x.reshape(num, -1)\n",
    "    size = data.shape[1]\n",
    "    means = np.mean(data, axis=1)\n",
    "    meansT = means.reshape(len(means), 1)\n",
    "    stds = np.std(data, axis=1)\n",
    "    stdsT = stds.reshape(len(stds), 1)\n",
    "    normalized = (data-meansT)/stdsT\n",
    "    normalized = normalized.reshape(num, d, w, h)\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(x, W, b):\n",
    "    conv = tf.nn.conv3d(x, W, strides=[1,2,2,2,1], padding='SAME')\n",
    "    conv = tf.math.add(conv, b)\n",
    "    return tf.nn.relu(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense(x, W, b):\n",
    "    return tf.matmul(x,W)+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x, W1, b1, W2, b2, W3, b3):\n",
    "    num = x.shape[0]\n",
    "    a1 = conv_layer(x, W1, b1)\n",
    "    a2 = conv_layer(a1, W2, b2)\n",
    "    flat = tf.reshape(a2, [num, -1])\n",
    "    out = dense(flat, W3, b3)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(corr, pred):\n",
    "    u = -corr*tf.math.log(pred)-(1.-corr)*tf.math.log(1.-pred)\n",
    "    a = tf.reduce_sum(u, axis = 1)\n",
    "    b = tf.reduce_mean(a)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = len(data)\n",
    "num_labels = len(labels)\n",
    "batch = 64\n",
    "epochs = 20\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n",
      "accuracy:  0.676\n",
      "loss at end of EPOCH: 1.0083\n",
      "time taken: 0.44s\n",
      "Done with EPOCH\n",
      "EPOCH 1\n",
      "accuracy:  0.718\n",
      "loss at end of EPOCH: 0.5370\n",
      "time taken: 0.42s\n",
      "Done with EPOCH\n",
      "EPOCH 2\n",
      "accuracy:  0.799\n",
      "loss at end of EPOCH: 0.3693\n",
      "time taken: 0.42s\n",
      "Done with EPOCH\n",
      "EPOCH 3\n",
      "accuracy:  0.888\n",
      "loss at end of EPOCH: 0.2730\n",
      "time taken: 0.53s\n",
      "Done with EPOCH\n",
      "EPOCH 4\n",
      "accuracy:  0.931\n",
      "loss at end of EPOCH: 0.2117\n",
      "time taken: 0.53s\n",
      "Done with EPOCH\n",
      "EPOCH 5\n",
      "accuracy:  0.955\n",
      "loss at end of EPOCH: 0.1702\n",
      "time taken: 0.51s\n",
      "Done with EPOCH\n",
      "EPOCH 6\n",
      "accuracy:  0.97\n",
      "loss at end of EPOCH: 0.1408\n",
      "time taken: 0.42s\n",
      "Done with EPOCH\n",
      "EPOCH 7\n",
      "accuracy:  0.984\n",
      "loss at end of EPOCH: 0.1192\n",
      "time taken: 0.42s\n",
      "Done with EPOCH\n",
      "EPOCH 8\n",
      "accuracy:  0.989\n",
      "loss at end of EPOCH: 0.1027\n",
      "time taken: 0.42s\n",
      "Done with EPOCH\n",
      "EPOCH 9\n",
      "accuracy:  0.993\n",
      "loss at end of EPOCH: 0.0897\n",
      "time taken: 0.51s\n",
      "Done with EPOCH\n",
      "EPOCH 10\n",
      "accuracy:  0.996\n",
      "loss at end of EPOCH: 0.0793\n",
      "time taken: 0.51s\n",
      "Done with EPOCH\n",
      "EPOCH 11\n",
      "accuracy:  0.996\n",
      "loss at end of EPOCH: 0.0708\n",
      "time taken: 0.42s\n",
      "Done with EPOCH\n",
      "EPOCH 12\n",
      "accuracy:  0.998\n",
      "loss at end of EPOCH: 0.0638\n",
      "time taken: 0.51s\n",
      "Done with EPOCH\n",
      "EPOCH 13\n",
      "accuracy:  0.999\n",
      "loss at end of EPOCH: 0.0579\n",
      "time taken: 0.42s\n",
      "Done with EPOCH\n",
      "EPOCH 14\n",
      "accuracy:  0.999\n",
      "loss at end of EPOCH: 0.0528\n",
      "time taken: 0.50s\n",
      "Done with EPOCH\n",
      "EPOCH 15\n",
      "accuracy:  0.999\n",
      "loss at end of EPOCH: 0.0485\n",
      "time taken: 0.47s\n",
      "Done with EPOCH\n",
      "EPOCH 16\n",
      "accuracy:  0.999\n",
      "loss at end of EPOCH: 0.0448\n",
      "time taken: 0.41s\n",
      "Done with EPOCH\n",
      "EPOCH 17\n",
      "accuracy:  0.999\n",
      "loss at end of EPOCH: 0.0415\n",
      "time taken: 0.45s\n",
      "Done with EPOCH\n",
      "EPOCH 18\n",
      "accuracy:  1.0\n",
      "loss at end of EPOCH: 0.0386\n",
      "time taken: 0.45s\n",
      "Done with EPOCH\n",
      "EPOCH 19\n",
      "accuracy:  1.0\n",
      "loss at end of EPOCH: 0.0360\n",
      "time taken: 0.41s\n",
      "Done with EPOCH\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    print(\"EPOCH\", i)\n",
    "    start = time.time()\n",
    "    total_loss = 0.\n",
    "    for j in range(0, num_samples, batch):\n",
    "        x = data[j:j+batch]\n",
    "        y = labels[j:j+batch]\n",
    "        with tf.GradientTape(persistent=True) as t:\n",
    "            out = model(x, W1, b1, W2, b2, W3, b3)\n",
    "            loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=out, labels=y))\n",
    "            total_loss += loss\n",
    "        W1.assign_sub(learning_rate*t.gradient(loss,W1))\n",
    "        b1.assign_sub(learning_rate*t.gradient(loss,b1))\n",
    "        W2.assign_sub(learning_rate*t.gradient(loss,W2))\n",
    "        b2.assign_sub(learning_rate*t.gradient(loss,b2))\n",
    "        W3.assign_sub(learning_rate*t.gradient(loss,W3))\n",
    "        b3.assign_sub(learning_rate*t.gradient(loss,b3))\n",
    "        del t\n",
    "    end = time.time()\n",
    "    mean_loss = total_loss/(num_samples//batch)\n",
    "    model_op = model(data, W1, b1, W2, b2, W3, b3)\n",
    "    correct_pred = tf.equal(tf.argmax(model_op, 1), tf.argmax(labels, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    print(\"accuracy: \", accuracy.numpy())\n",
    "    print(\"loss at end of EPOCH: %0.4f\" % mean_loss)\n",
    "    print(\"time taken: {:0.2f}s\".format(end-start))\n",
    "    print(\"Done with EPOCH\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
